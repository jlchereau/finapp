{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa23b0",
   "metadata": {},
   "source": [
    "# Llama-Index Workflow Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "124197b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02783246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.utils.workflow import (\n",
    "    draw_all_possible_flows,\n",
    "    draw_most_recent_execution,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10242251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from typing import Any\n",
    "from workflows import Context, Workflow, step\n",
    "from workflows.errors import WorkflowRuntimeError\n",
    "from workflows.events import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    ")\n",
    "\n",
    "class DispatchEvent(Event):\n",
    "    pass\n",
    "\n",
    "class FetchDataEvent(Event):\n",
    "    \"\"\"Event to trigger data collection with a query\"\"\"\n",
    "    query: str\n",
    "\n",
    "class ResponseDataEvent(Event):\n",
    "    \"\"\"Event to return data collected to the following step\"\"\"\n",
    "    data: Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aefda7e",
   "metadata": {},
   "source": [
    "## First Pattern: Single Data Collection from One Provider\n",
    "\n",
    "Docs:\n",
    "- https://docs.llamaindex.ai/en/stable/workflows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74859f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL -> 0.2041220296720596\n"
     ]
    }
   ],
   "source": [
    "class Pattern1Workflow(Workflow):\n",
    "    \"\"\"\n",
    "    Pattern1Workflow launches a single data collection using one provider \n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # create providers\n",
    "        self.provider = random\n",
    "\n",
    "    @step\n",
    "    async def fetch_data(self, ev: StartEvent) -> StopEvent:\n",
    "        \"\"\"\n",
    "        Entry step initiated by StartEvent\n",
    "        Running w.run(query=\"MSFT\") where w is an instantiate Workflow\n",
    "        makes query available on StartEvent (which can be subclassed)\n",
    "        In this very simple scenario it is also the exit step\n",
    "        raising StopEvent.\n",
    "        Like functions, if there are two many instructions in this step\n",
    "        It would make sense to break the step into two or more\n",
    "        sequantial step where the returned event of the previous step\n",
    "        is the ev parameter of the fucntion decorated with @step\n",
    "        that implements the next step in the sequence.\n",
    "        \"\"\"\n",
    "        query = ev.query # possibly a ticker\n",
    "        # Collect data with provider1\n",
    "        d = self.provider()\n",
    "        # Do some data processing if needed\n",
    "        result = query + \" -> \" + str(d)\n",
    "        # Return an event to allow next step to follow sequentially\n",
    "        return StopEvent(result=result)\n",
    "\n",
    "try:\n",
    "    w = Pattern1Workflow()\n",
    "    result = await w.run(query=\"AAPL\")\n",
    "    print(result)\n",
    "except WorkflowRuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3d554c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flows/pattern_1.html\n"
     ]
    }
   ],
   "source": [
    "draw_all_possible_flows(Pattern1Workflow, filename=\"flows/pattern_1.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc55a61",
   "metadata": {},
   "source": [
    "## Second Pattern: Collect and Combine Data From Various Providers\n",
    "\n",
    "Docs:\n",
    "- https://docs.llamaindex.ai/en/stable/examples/workflow/workflows_cookbook/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cd65f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetchData1Event(FetchDataEvent):\n",
    "    \"\"\"Event to trigger the data collection with provider1\"\"\"\n",
    "    pass\n",
    "\n",
    "class FetchData2Event(FetchDataEvent):\n",
    "    \"\"\"Event to trigger the data collection with provider2\"\"\"\n",
    "    pass\n",
    "\n",
    "class ResponseData1Event(ResponseDataEvent):\n",
    "    \"\"\"Event to pass the data collection with provider1 to the following step\"\"\"\n",
    "    pass\n",
    "\n",
    "class ResponseData2Event(ResponseDataEvent):\n",
    "    \"\"\"Event to pass the data collection with provider2 to the following step\"\"\"\n",
    "    pass\n",
    "\n",
    "class Pattern2Workflow(Workflow):\n",
    "    \"\"\"\n",
    "    Pattern2Workflow launches parallel data collection using providers \n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # create providers\n",
    "        self.provider1 = random\n",
    "        self.provider2 = random\n",
    "\n",
    "    @step\n",
    "    async def dispatch(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> FetchData1Event | FetchData2Event | DispatchEvent:\n",
    "        \"\"\"\n",
    "        Entry step initiated by StartEvent\n",
    "        Running w.run(query=\"MSFT\") where w is an instantiate Workflow\n",
    "        makes query available on StartEvent (which can be subclassed)\n",
    "        \"\"\"\n",
    "        query = ev.query # possibly a ticker\n",
    "        # Do some setup/prep work here\n",
    "        # ...\n",
    "        # Make data available to other steps\n",
    "        await ctx.store.set(\"query\", query)\n",
    "        # Manually send events to trigger parallel steps (return is sequential)\n",
    "        ctx.send_event(FetchData1Event(query=query))\n",
    "        ctx.send_event(FetchData2Event(query=query))\n",
    "        # We need to return an event anyway\n",
    "        return DispatchEvent()\n",
    "\n",
    "    @step\n",
    "    async def fetch_data_1(self, ev: FetchData1Event) -> ResponseData1Event:\n",
    "        \"\"\"\n",
    "        Step triggered by FetchData1Event to collect data with provider1\n",
    "        \"\"\"\n",
    "        # Collect data with provider1\n",
    "        d = self.provider1()\n",
    "        # Do some data processing if needed\n",
    "        data = \"1. \" + ev.query + \" -> \" + str(d)\n",
    "        # Return an event to allow next step to follow sequentially\n",
    "        return ResponseData1Event(data=data)\n",
    "\n",
    "    @step\n",
    "    async def fetch_data_2(self, ev: FetchData2Event) -> ResponseData2Event:\n",
    "        \"\"\"\n",
    "        Step triggered by FetchData2Event to collect data with provider2\n",
    "        \"\"\"\n",
    "        # Collect data with provider 2\n",
    "        d = self.provider2()\n",
    "        # Do some data processing if needed \n",
    "        data = \"2. \" + ev.query + \" -> \" + str(d)\n",
    "        # Return an event to allow next step to follow sequentially\n",
    "        return ResponseData2Event(data=data)\n",
    "\n",
    "    @step\n",
    "    async def combine(\n",
    "        self, ctx: Context, ev: DispatchEvent | ResponseData1Event | ResponseData2Event\n",
    "    ) -> StopEvent | None:\n",
    "        \"\"\"\n",
    "        Exit step where all events (and data) combine\n",
    "        \"\"\"\n",
    "        # Continue waiting after receiving DispatchEvent\n",
    "        if isinstance(ev, DispatchEvent):\n",
    "            return None\n",
    "        # Wait for receiving both ResponseData1Event and ResponseData2Event\n",
    "        events = ctx.collect_events(ev, [ResponseData1Event, ResponseData2Event])\n",
    "        if not events:\n",
    "            return None\n",
    "        # All required events received to process this step\n",
    "        ev1, ev2 = events\n",
    "        # Get data made available to all steps via context store\n",
    "        query = await ctx.store.get(\"query\")\n",
    "        # Do some further data processing if needed\n",
    "        result = { \"query\": query, \"data\": [ev1.data, ev2.data]}\n",
    "        # Return the result in a StopEvent which exits the workflow\n",
    "        # Note that StopEvent can be subclassed\n",
    "        return StopEvent(result=result)\n",
    "\n",
    "try:\n",
    "    w = Pattern2Workflow()\n",
    "    result = await w.run(query=\"AAPL\")\n",
    "    result[\"data\"]\n",
    "except WorkflowRuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35227bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flows/pattern_2.html\n"
     ]
    }
   ],
   "source": [
    "draw_all_possible_flows(Pattern2Workflow, filename=\"flows/pattern_2.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe61fdf",
   "metadata": {},
   "source": [
    "### Third Pattern: Iterate to Collect Data from the Same Provider and Combine\n",
    "\n",
    "Docs:\n",
    "- https://docs.llamaindex.ai/en/stable/examples/workflow/parallel_execution/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41e84c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL -> 0.5534719916765076', 'GOOG -> 0.37682825392136343', 'MSFT -> 0.9931788901406868']\n"
     ]
    }
   ],
   "source": [
    "class Pattern3Workflow(Workflow):\n",
    "    \"\"\"\n",
    "    Pattern3Workflow launches parallel data collection using one provider\n",
    "    and several queries \n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # create providers\n",
    "        self.provider = random\n",
    "\n",
    "    @step\n",
    "    async def dispatch(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> FetchDataEvent | DispatchEvent:\n",
    "        \"\"\"\n",
    "        Entry step initiated by StartEvent\n",
    "        Running w.run(query=[\"AAPL\", \"GOOG\", \"MSFT\"])\n",
    "        where w is an instantiate Workflow\n",
    "        makes query available on StartEvent (which can be subclassed)\n",
    "        \"\"\"\n",
    "        queries = ev.queries # possibly a list of tickers\n",
    "        # Do some setup/prep work here\n",
    "        # ...\n",
    "        # Make data available to other steps\n",
    "        # Here we need to know how many FetchDataEvent we need to collect\n",
    "        await ctx.store.set(\"num_to_collect\", len(queries))\n",
    "        # Manually send events to trigger parallel steps (return is sequential)\n",
    "        for query in queries:\n",
    "            ctx.send_event(FetchDataEvent(query=query))\n",
    "        # We need to return an event anyway\n",
    "        return DispatchEvent()\n",
    "\n",
    "    @step(num_workers=3) # We can define the number of workers (defaults to 4)\n",
    "    async def fetch_data(self, ev: FetchDataEvent) -> ResponseDataEvent:\n",
    "        \"\"\"\n",
    "        Step triggered by FetchDataEvent to collect data with provider\n",
    "        Step will run for each query in queries in parallel \n",
    "        \"\"\"\n",
    "        # Collect data from a provider\n",
    "        d = self.provider()\n",
    "        # Do some data processing if needed \n",
    "        data = ev.query + \" -> \" + str(d)\n",
    "         # Return an event to allow next step to follow sequentially\n",
    "        return ResponseDataEvent(data=data)\n",
    "\n",
    "    @step\n",
    "    async def combine(\n",
    "        self, ctx: Context, ev: DispatchEvent | ResponseDataEvent\n",
    "    ) -> StopEvent | None:\n",
    "        \"\"\"\n",
    "        Exit step where all events (and data) combine\n",
    "        \"\"\"\n",
    "        # Continue waiting after receiving DispatchEvent\n",
    "        if isinstance(ev, DispatchEvent):\n",
    "            return None\n",
    "        # Wait for all events to finish (we know how many to collect)\n",
    "        num_to_collect = await ctx.store.get(\"num_to_collect\")\n",
    "        events = ctx.collect_events(ev, [ResponseDataEvent] * num_to_collect)\n",
    "        if not events:\n",
    "            return None\n",
    "        # Do some further data processing if needed\n",
    "        result = [ev.data for ev in events]\n",
    "        # Return the result in a StopEvent which exits the workflow\n",
    "        # Note that StopEvent can be subclassed\n",
    "        return StopEvent(result=result)\n",
    "\n",
    "try:\n",
    "    w = Pattern3Workflow()\n",
    "    result = await w.run(queries=[\"AAPL\", \"GOOG\", \"MSFT\"])\n",
    "    print(result)\n",
    "except WorkflowRuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e6a6e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flows/pattern_3.html\n"
     ]
    }
   ],
   "source": [
    "draw_all_possible_flows(Pattern3Workflow, filename=\"flows/pattern_3.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ae385",
   "metadata": {},
   "source": [
    "# Fourth Pattern: Exception Management\n",
    "\n",
    "In most cases, the flow is useless if one of the steps fails. In such case, let exceptions bubble.\n",
    "\n",
    "In some cases, for example when displaying several tickers, it is worthwhile to catch exceptions within each step and to return a mix of data (successsful tickers) and exceptions (failed tickers) in the returned event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdf6c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't deal with AAPL\n"
     ]
    }
   ],
   "source": [
    "# Stubs for @app.lib.exceptions\n",
    "class ProviderException(Exception):\n",
    "    pass\n",
    "\n",
    "class WorkflowException(Exception):\n",
    "    pass\n",
    "\n",
    "class Pattern4Workflow(Workflow):\n",
    "    \"\"\"\n",
    "    Pattern4Workflow fails\n",
    "    \"\"\"\n",
    "\n",
    "    @step\n",
    "    async def fetch_data(self, ev: StartEvent) -> StopEvent:\n",
    "        \"\"\"\n",
    "        A step that raises an exception\n",
    "        Only raise WorkflowException to avoid too-broad-exception warnings\n",
    "        Do not catch other exceptions in steps, let them bubble up\n",
    "        to be handled by the workflow engine so that we only end up\n",
    "        with WorkflowException or ProviderException in the end.\n",
    "        These exceptions shall be handled by the global exception handler\n",
    "        in the UI layer to display a toast message to the user.\n",
    "        \"\"\"\n",
    "        raise WorkflowException(f\"Can't deal with {ev.query}\")\n",
    "        return StopEvent\n",
    "\n",
    "try:\n",
    "    w = Pattern4Workflow()\n",
    "    result = await w.run(query=\"AAPL\")\n",
    "    print(result)\n",
    "except ProviderException as e:\n",
    "    # raise e (let it bubble up)\n",
    "    print(e)\n",
    "except WorkflowException as e:\n",
    "    # raise e (let it bubble up)\n",
    "    print(e)\n",
    "except WorkflowRuntimeError as e:\n",
    "    # raise a WorkflowException instead\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
